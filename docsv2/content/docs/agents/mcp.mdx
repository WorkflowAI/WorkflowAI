---
title: Model Context Protocol (MCP)
summary: Documentation on using the Model Context Protocol (MCP) to connect AI agents to external data and tools. Covers MCP concepts, provider comparisons, and implementation with WorkflowAI.
description: Learn how to use MCP servers with WorkflowAI
---

<Callout type="warning">
This guide is a work in progress and is not ready to be published.
</Callout>

The Model Context Protocol (MCP) is an open standard that enables AI models to securely connect to external data sources and tools. Think of MCP like a USB-C port for AI applications - it provides a standardized way to connect AI models to different systems, databases, and services.

WorkflowAI supports MCP integration through the OpenAI-compatible chat/completions endpoint, allowing you to leverage the growing ecosystem of MCP servers with any model supported by WorkflowAI.

## What is MCP?

MCP allows AI models to access:
- **External data sources** (databases, file systems, APIs)
- **Live information** (real-time data, current state)
- **Specialized tools** (code execution, analysis tools)
- **Business systems** (CRM, documentation, internal tools)

Unlike static data or pre-trained knowledge, MCP enables models to access up-to-date, contextual information during the conversation.

## MCP vs Traditional Tools

| Feature | **Traditional Tools** | **MCP Servers** |
|---------|---------------------|-----------------|
| **Setup** | Define individual functions | Connect to pre-built servers |
| **Scope** | Single function per tool | Multiple related tools per server |
| **Maintenance** | Custom code required | Server maintained by community |
| **Discovery** | Manual tool definition | Automatic tool discovery |
| **Context** | Limited to function parameters | Rich contextual data access |

## Provider Implementation Comparison

Before diving into WorkflowAI's approach, let's compare how OpenAI, Anthropic, and Mistral implement MCP:

### OpenAI Implementation (Responses API)

**Approach**: Tool-centric configuration via Responses API

```bash
curl https://api.openai.com/v1/responses \
  -H "Content-Type: application/json" \
  -H "Authorization: Bearer $OPENAI_API_KEY" \
  -d '{
    "model": "gpt-4.1",
    "tools": [
      {
        "type": "mcp",
        "server_label": "github",
        "server_url": "https://mcp.github.com/sse",
        "allowed_tools": ["search_repositories", "create_issue"],
        "require_approval": "never"
      }
    ],
    "input": "Check my repositories for security issues"
  }'
```

**Key Characteristics:**
- **Endpoint**: Uses `/v1/responses` (not chat/completions)
- **Configuration**: MCP servers configured in `tools` array with `type: "mcp"`
- **Tool Filtering**: `allowed_tools` parameter to limit available tools
- **Approval Control**: `require_approval` parameter for security
- **Server Identification**: `server_label` for naming servers

### Anthropic Implementation (Messages API)

**Approach**: Parameter-centric configuration via Messages API

```bash
curl https://api.anthropic.com/v1/messages \
  -H "Content-Type: application/json" \
  -H "X-API-Key: $ANTHROPIC_API_KEY" \
  -H "anthropic-version: 2023-06-01" \
  -H "anthropic-beta: mcp-client-2025-04-04" \
  -d '{
    "model": "claude-sonnet-4-20250514",
    "max_tokens": 1000,
    "messages": [{"role": "user", "content": "Check my repositories for security issues"}],
    "mcp_servers": [
      {
        "type": "url",
        "url": "https://mcp.github.com/sse",
        "name": "github",
        "authorization_token": "ghp_xxxxxxxxxxxx",
        "tool_configuration": {
          "enabled": true,
          "allowed_tools": ["search_repositories", "create_issue"]
        }
      }
    ]
  }'
```

**Key Characteristics:**
- **Endpoint**: Uses standard `/v1/messages` API
- **Configuration**: Dedicated `mcp_servers` parameter
- **Beta Feature**: Requires `anthropic-beta: mcp-client-2025-04-04` header
- **Tool Control**: `tool_configuration` object for fine-grained control
- **Authentication**: Direct `authorization_token` in server config

### Mistral Implementation

**Approach**: Agent-centric configuration with Python SDK

**Note**: Mistral provides CURL examples for their general `/v1/agents/completions` API, but their MCP documentation only shows Python SDK examples, not raw API calls.

```python
# Python SDK example from Mistral docs
from mistralai import Mistral
from mistralai.extra.run.context import RunContext
from mistralai.extra.mcp.sse import MCPClientSSE, SSEServerParams

client = Mistral(api_key=api_key)
server_url = "https://mcp.github.com/sse"
mcp_client = MCPClientSSE(sse_params=SSEServerParams(url=server_url))

async with RunContext(model="mistral-medium-latest") as run_ctx:
    await run_ctx.register_mcp_client(mcp_client=mcp_client)
    
    run_result = await client.beta.conversations.run_async(
        run_ctx=run_ctx,
        inputs="Check my repositories for security issues"
    )
```

**Key Characteristics:**
- **Endpoint**: Uses `/v1/agents/completions` via Python SDK
- **Configuration**: MCP servers registered via `RunContext` and `register_mcp_client()`
- **Agent Management**: Agents created with `/v1/agents` endpoint
- **Python-Only**: No raw CURL examples for MCP integration
- **Conversation-Based**: Uses `conversations.run_async()` for execution

### WorkflowAI Hybrid Approach

**Best of Both Worlds**: Maintains OpenAI compatibility while offering flexible configuration

```bash
# Option 1: Extended tools parameter (OpenAI-style)
curl https://run.workflowai.com/v1/chat/completions \
  -H "Content-Type: application/json" \
  -H "Authorization: Bearer wai-xxx" \
  -d '{
    "model": "claude-3-7-sonnet-latest",
    "messages": [{"role": "user", "content": "Check my repositories for security issues"}],
    "metadata": {"agent_id": "security-analyst"},
    "tools": [
      {
        "type": "mcp_server",
        "mcp_server": {
          "type": "sse",
          "name": "github",
          "url": "https://mcp.github.com/sse",
          "auth": {"type": "bearer", "token": "ghp_xxx"},
          "allowed_tools": ["search_repositories", "create_issue"]
        }
      }
    ]
  }'

# Option 2: Dedicated mcp_servers parameter (Anthropic-style)
curl https://run.workflowai.com/v1/chat/completions \
  -H "Content-Type: application/json" \
  -H "Authorization: Bearer wai-xxx" \
  -d '{
    "model": "claude-3-7-sonnet-latest",
    "messages": [{"role": "user", "content": "Check my repositories for security issues"}],
    "metadata": {"agent_id": "security-analyst"},
    "extra_body": {
      "mcp_servers": [
        {
          "type": "sse",
          "name": "github", 
          "url": "https://mcp.github.com/sse",
          "auth": {"type": "bearer", "token": "ghp_xxx"},
          "allowed_tools": ["search_repositories", "create_issue"]
        }
      ]
    }
  }'
```

**Key Advantages:**
- **Full OpenAI Compatibility**: Uses standard `/v1/chat/completions` endpoint
- **Flexible Configuration**: Both tools-based and parameter-based approaches
- **Agent Integration**: Works with WorkflowAI's agent/version/deployment system
- **No Beta Headers**: Production-ready without experimental flags

### API Specification Comparison

| Feature | **OpenAI** | **Anthropic** | **Mistral** | **WorkflowAI** |
|---------|------------|---------------|-------------|----------------|
| **MCP Documentation** | CURL examples | CURL examples | Python SDK only | Both options |
| **Endpoint** | `/v1/responses` | `/v1/messages` | `/v1/agents/completions` | `/v1/chat/completions` |
| **Beta Required** | No | Yes (`mcp-client-2025-04-04`) | No | No |
| **MCP Location** | `tools` array | `mcp_servers` parameter | `RunContext.register_mcp_client()` | Both options |
| **Tool Filtering** | `allowed_tools` | `tool_configuration.allowed_tools` | Not documented | `allowed_tools` |
| **Authentication** | Headers/URL params | `authorization_token` | SDK OAuth flows | `auth` object |
| **Multi-server** | Multiple tool entries | Array of servers | Multiple `register_mcp_client()` calls | Both patterns |
| **OpenAI Compat** | Different endpoint | Different API | Different paradigm | Full compatibility |

## Supported MCP Server Types

WorkflowAI focuses exclusively on remote MCP servers:

### SSE Servers (Server-Sent Events)
Remote servers using Server-Sent Events. Perfect for real-time data and cloud services.

```python
client.chat.completions.create(
    model="claude-3-7-sonnet-latest", 
    messages=[{"role": "user", "content": "Check this code for vulnerabilities"}],
    metadata={"agent_id": "security-analyst"},
    extra_body={
        "mcp_servers": [{
            "type": "sse",
            "name": "semgrep",
            "url": "https://mcp.semgrep.ai/sse"
        }]
    }
)
```

### HTTP Servers (Streamable)
Servers using streamable HTTP transport for high-performance scenarios.

```python
client.chat.completions.create(
    model="gemini-2.5-pro-preview",
    messages=[{"role": "user", "content": "Analyze sales data from Q4"}],
    metadata={"agent_id": "data-analyst"},
    extra_body={
        "mcp_servers": [{
            "type": "http",
            "name": "analytics",
            "url": "https://api.example.com/mcp",
            "headers": {"Authorization": "Bearer token"}
        }]
    }
)
```

## Authentication Strategies

WorkflowAI supports two authentication approaches for MCP servers:

### Strategy 1: UI-Configured Authentication

Configure authentication credentials in the WorkflowAI web application for reusable, secure access:

**TODO**: Setting API keys from the UI might not work properly - this behavior needs to be determined

**In WorkflowAI UI:**
1. Navigate to Agent Settings â†’ MCP Servers
2. Add server with authentication details
3. Configure OAuth flows or store API keys securely

### Strategy 2: Dynamic Authentication

Pass authentication details directly in API requests for dynamic or temporary access:

```python
# Dynamic authentication in request
client.chat.completions.create(
    model="gpt-4o",
    messages=[{"role": "user", "content": "Search GitHub repositories"}],
    metadata={"agent_id": "research-assistant"},
    extra_body={
        "mcp_servers": [{
            "type": "sse",
            "name": "github",
            "url": "https://mcp.github.com/sse",
            "auth": {
                "type": "bearer",
                "token": os.getenv("GITHUB_TOKEN")
            }
        }]
    }
)
```

## Authentication Configuration

### Bearer Token Authentication
```python
{
    "mcp_servers": [{
        "type": "sse", 
        "name": "github",
        "url": "https://mcp.github.com/sse",
        "auth": {
            "type": "bearer",
            "token": "ghp_xxxxxxxxxxxx"
        }
    }]
}
```