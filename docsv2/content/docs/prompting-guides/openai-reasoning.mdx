---
title: OpenAI Reasoning Models - Best Practices
description: Best practices for prompting OpenAI's reasoning models (o1, o3, o4-mini) to maximize performance and reliability using the chat completions endpoint.
---

import { Callout } from 'fumadocs-ui/components/callout';

<Callout type="info">
This guide is compiled from OpenAI's official documentation and adapted for WorkflowAI's chat completions endpoint. For the most up-to-date information, refer to [OpenAI's original resources](https://cookbook.openai.com/examples/o-series/o3o4-mini_prompting_guide).
</Callout>

## Overview

OpenAI's o-series reasoning models (o1, o3, o4-mini) are trained to think for longer before responding, making them the smartest models available. These models are trained to use tools natively within their chain of thought (CoT), which unlocks improved reasoning capabilities around when and how to use tools.

## Key Concepts

### System Messages and Instructions

For reasoning models, use clear system messages to provide instructions. The models are designed to follow detailed instructions effectively while maintaining their internal reasoning process.

## Best Practices for Function Calling

### Context Setting via System Message

#### 1. General Context
Role prompting is helpful in setting the base behavior, tone and outlining the set of actions that are possible:

```python
messages = [
    {
        "role": "system", 
        "content": """You are an AI retail agent.

As a retail agent, you can help users cancel or modify pending orders, return or exchange delivered orders, modify their default user address, or provide information about their own profile, orders, and related products."""
    },
    {"role": "user", "content": "I need help with my order"}
]
```

#### 2. Function Call Ordering
o3/o4-mini models can make mistakes in the order of tool calls. To guard against these cases, explicitly outline the orders to accomplish certain tasks:

```python
system_content = """
Before creating files, check to see if directories exist first.

To process a refund for a delivered order, follow these steps:
1. Confirm the order was delivered. Use: `order_status_check`
2. Check the refund eligibility policy. Use: `refund_policy_check`
3. Create the refund request. Use: `refund_create`
4. Notify the user of refund status. Use: `user_notify`
"""
```

#### 3. Defining Boundaries on Tool Usage
Clarify when and when not to invoke certain tools:

```python
system_message = """
Be proactive in using tools to accomplish the user's goal. If a task cannot be completed with a single step, keep going and use multiple tools as needed until the task is completed. Do not stop at the first failure. Try alternative steps or tool combinations until you succeed.

- Use tools when:
  - The user wants to cancel or modify an order.
  - The user wants to return or exchange a delivered product.
  - The user wants to update their address or contact details.
  - The user asks for current or personalized order or profile info.

- Do not use tools when:
  - The user asks a general question like "What's your return policy?"
  - The user asks something outside your retail role (e.g., "Write a poem").

If a task is not possible due to real constraints, explain why clearly and do not call tools blindly.
"""
```

### Function Description Best Practices

#### 1. Usage Criteria
Refine how a function gets called at the function description level:

```python
tools = [{
    "type": "function",
    "name": "create_file",
    "description": """Creates a new file with the specified name and contents in a target directory. This function should be used when persistent storage is needed and the file does not already exist.
- Only call this function if the target directory exists. Check first using the `directory_check` tool.  
- Do not use for temporary or one-off content—prefer direct responses for those cases.  
- Do not overwrite existing files. Always ensure the file name is unique.
- If replacement is intended and confirmed, use `file_delete` followed by `file_create`, or use `file_update` instead.""",
    "parameters": {
        "type": "object",
        "properties": {
            "filename": {"type": "string", "description": "Name of the file to create"},
            "content": {"type": "string", "description": "Content to write to the file"}
        },
        "required": ["filename", "content"],
        "additionalProperties": False
    },
    "strict": True
}]
```

#### 2. Few-Shot Prompting
While reasoning models do not benefit from few-shot prompting as much as non-reasoning models, few-shot prompting can improve tool calling performance:

```python
system_message = """
Use this tool to run fast, exact regex searches over text files using the `ripgrep` engine.

- Always escape special regex characters: ( ) [ ] { } + * ? ^ $ | . \\
- Use `\\` to escape any of these characters when they appear in your search string.
- Do NOT perform fuzzy or semantic matches.
- Return only a valid regex pattern string.

Examples:
Literal            -> Regex Pattern         
function(          -> function\\(           
value[index]       -> value\\[index\\]      
file.txt           -> file\\.txt            
user|admin         -> user\\|admin          
path\to\file       -> path\\\\to\\\\file     
"""
```

#### 3. Key Rules Up Front
Place the most important rules and constraints at the beginning of function descriptions.

### Guarding Against Function Calling Hallucinations

<Callout type="warning">
The o3 model may be more prone to hallucinations than other models. These hallucinations may appear as the model promising to call tools in the background without actually doing so, or promising to call a tool in future turns.
</Callout>

#### 1. Explicit Instructions
Explicitly instruct the model to avoid common hallucinations:

```python
system_message = """
Do NOT promise to call a function later. If a function call is required, emit it now; otherwise respond normally.
"""
```

#### 2. Catch Bad Arguments Early
Setting `strict` to `true` will ensure function calls reliably adhere to the function schema. We recommend turning it on whenever possible.

If your arguments have additional complex format requirements, add validation instructions:

```python
system_message = """
Validate arguments against the expected format before making function calls; if you are unsure, ask for clarification instead of guessing.
"""
```

#### 3. Addressing Lazy Behavior
In rare instances of lazy behavior from o3:

- **Start new conversations for unrelated topics**: When switching to a new or unrelated topic, begin a fresh conversation thread
- **Manage conversation history**: If the conversation history contains many irrelevant tool calls or outputs, summarize the important information and start with a cleaner context

### Avoid Chain of Thought Prompting

<Callout type="info">
Since these models are reasoning models and produce an internal chain of thought, they do not need to be explicitly prompted to plan and reason between tool calls.
</Callout>

Do not try to induce additional reasoning before each function call by asking the model to plan more extensively. Asking a reasoning model to reason more may actually hurt performance.

## Working with Chat Completions

### Basic Example with Function Calling

```python
import openai

client = openai.OpenAI(
    api_key="YOUR_WORKFLOWAI_API_KEY",
    base_url="https://run.workflowai.com/v1"
)

def get_weather(latitude, longitude):
    # Your weather API implementation
    return f"Temperature at {latitude}, {longitude}: 22°C"

tools = [{
    "type": "function",
    "name": "get_weather",
    "description": "Get current temperature for provided coordinates in celsius.",
    "parameters": {
        "type": "object",
        "properties": {
            "latitude": {"type": "number"},
            "longitude": {"type": "number"}
        },
        "required": ["latitude", "longitude"],
        "additionalProperties": False
    },
    "strict": True
}]

messages = [
    {"role": "user", "content": "What's the weather like in Paris today?"}
]

response = client.chat.completions.create(
    model="o3-mini",  # or your preferred reasoning model
    messages=messages,
    tools=tools,
    metadata={"agent_id": "weather-agent"}
)

# Handle function calling
if response.choices[0].message.tool_calls:
    # Process tool calls and continue conversation
    tool_call = response.choices[0].message.tool_calls[0]
    if tool_call.function.name == "get_weather":
        args = json.loads(tool_call.function.arguments)
        result = get_weather(args["latitude"], args["longitude"])
        
        # Add the assistant's response and tool result to conversation
        messages.append(response.choices[0].message)
        messages.append({
            "role": "tool",
            "tool_call_id": tool_call.id,
            "content": result
        })
        
        # Get final response
        final_response = client.chat.completions.create(
            model="o3-mini",
            messages=messages,
            metadata={"agent_id": "weather-agent"}
        )
        
        print(final_response.choices[0].message.content)
```

### Tool Usage Boundaries
When mixing multiple tools, explicitly define tool usage boundaries in the system prompt:

```python
system_message = """
You are a helpful research assistant with access to the following tools:
- calculator: for basic arithmetic or unit conversions when speed is preferred
- code_interpreter: for any computation involving math, statistics, or code execution

Always use the code_interpreter for anything involving logic, scripts, or multistep math. Use the calculator tool only for simple 1-step math problems.
"""
```

### Clarifying When Internal Knowledge Is Not Sufficient
Even though o3/o4-mini models can often solve tasks on their own, tools may provide more reliable answers:

```python
system_message = """
You have access to tools for specific tasks. Always prefer using the appropriate tool when a user asks a question involving:
- math problems
- data analysis
- generating or executing code
- formatting or transforming structured text

Avoid doing these directly in your own response. Always use the tool instead.
"""
```

## Common Questions

### How Many Functions Is Too Many?
For o3 and o4-mini models, any setup with fewer than ~100 tools and fewer than ~20 arguments per tool is considered in-distribution and should perform within expected reliability bounds.

However, more tools can introduce ambiguity or confusion:
- **Function description clarity becomes critical**: If multiple tools have overlapping purposes or vague descriptions, models may call the wrong one
- **Tool list size can affect latency and reasoning depth**: Longer lists mean the model has more options to parse during reasoning
- **Tool hallucinations can increase with complexity**: Especially with o3, there have been reports of hallucinated tool calls when the toolset is large and under-defined

### Should I Use Nested Parameters or Flat Schemas?
There's no hard guidance, but flat structures are often easier for the model to reason about. With deeply nested objects, especially ones with repeated or semantically similar field names, the model is more likely to omit or misuse arguments.

For domains that naturally involve structured input, nesting helps organize related parameters, but you must use techniques like clear field descriptions, anyOf logic, or strict schemas to guard against invalid argument combinations.

## Original Sources

This guide is compiled and adapted from:
- [OpenAI's o3/o4-mini Function Calling Guide](https://cookbook.openai.com/examples/o-series/o3o4-mini_prompting_guide)
- [OpenAI Platform Documentation](https://platform.openai.com/docs/guides/reasoning-best-practices)

For the most current information and additional examples, refer to these original sources. 
