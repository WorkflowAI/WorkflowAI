---
title: Why WorkflowAI?
summary: "Discover why WorkflowAI is the leading open-source platform for AI agents. Learn about our commitment to provider agnosticism, open source, and a superior Agent Experience (AX)."
description: WorkflowAI is the open-source platform for AI agents.
---

WorkflowAI empowers developers to build production-ready AI agents without the complexity of managing infrastructure, model providers, or observability systems. We provide a unified platform that works with the best models from every provider, enabling you to focus on building exceptional AI experiences rather than wrestling with infrastructure challenges.

## WorkflowAI is a OpenAI API compatible platform

Built on OpenAI's API standard means your existing code works immediately.

This approach delivers **[zero migration complexity](/docs/quickstarts)** for existing OpenAI-based applications, **easy integration** with your current development workflow, **freedom to move** your code elsewhere if needed, and a **pro-ecosystem approach** that works with your preferred frameworks and tools.

WorkflowAI is pro-ecosystem and pro-integration. We encourage you to build with the frameworks, platforms, and services that best fit your requirements, and we work to [enable seamless integration with your existing tech stack](/docs/quickstarts#integrations).

## WorkflowAI is designed for Agent Experience (AX)

**WorkflowAI is designed to provide the best [Agent Experience (AX)](https://biilmann.blog/articles/introducing-ax/) in the industry.**

Just as companies learned to optimize for User Experience (UX) and Developer Experience (DX), WorkflowAI optimizes for AX - the holistic experience AI agents have when using our platform. We're accessible in all major MCP clients and IDEs, with agent-optimized APIs and machine-ready documentation.

This means your favorite agents - ChatGPT, Claude, Cursor, or any AI assistant - can seamlessly leverage WorkflowAI's full capabilities. You can drive complex workflows with high-level goals while agents handle the operational complexity, making them exponentially more capable when working with WorkflowAI.

*TODO: Polish and expand this section with specific examples and use cases*

## WorkflowAI is provider agnostic

Today's best AI models don't come from just one provider. Leading companies like AI Cursor use models from Anthropic, Google, and OpenAI strategically, choosing the right model for each specific task. WorkflowAI enables this same flexibility without vendor lock-in.

We provide access to [cutting-edge models from all major providers](/docs/inference/models) through a single API that just works everywhere. Your team can **choose the best model for each task** without rewriting application code, **switch between providers instantly** as new models are released, and **avoid vendor lock-in** that limits your technology choices. This lets you **focus on building agents** instead of managing multiple API integrations.

While large engineering teams like [Harvey AI](https://www.harvey.ai/blog/resilient-ai-infrastructure) can build their own AI infrastructure, we believe most teams benefit from using a proven open-source solution that handles this complexity for them.

## WorkflowAI is open source

WorkflowAI is completely open source under the [Apache 2.0 license](https://github.com/workflowai/workflowai/blob/main/LICENSE). This provides **complete transparency** in how your AI infrastructure works, eliminates **vendor lock-in** with proprietary systems, enables **community-driven development** with contributions from developers worldwide, and offers **self-hosting options** for teams that need complete control.

We believe open source is the future of AI infrastructure. By choosing the most permissive license and inviting the community to participate, we're building the standard for AI agent platforms that benefits everyone.

## WorkflowAI doesn't lock you in

**As a true OpenAI API compatible platform, there's no lock-in with WorkflowAI.**

Building on WorkflowAI is building on the OpenAI API standard. If you're already using OpenAI or any OpenAI-compatible service, getting started is seamless. Simply change your base URL and you're running on WorkflowAI's infrastructure.

If you need to move away, you won't have to tear apart your application to remove proprietary layers. Your code works with any OpenAI-compatible provider because we don't introduce vendor-specific APIs or data formats.

## WorkflowAI is fully managed

Building reliable AI infrastructure requires solving complex challenges: multi-region deployments for high availability, real-time monitoring across dozens of models, scaling observability systems for high-volume workloads, managing failover between providers, and ensuring regular maintenance and backups.

As a fully managed platform, WorkflowAI handles these operational burdens so you can focus on what matters most: building exceptional AI agents. We manage your **inference infrastructure** with [multi-region redundancy](/docs/inference/reliability) and 24/7 monitoring, provide **[observability](/docs/observability)** that scales with your application volume, ensure **[provider failover](/docs/inference/reliability)** and manage rate limits efficiently for maximum reliability, manage [tools](/docs/agents/tools) for your agents, deliver **performance optimization** across different model types and providers, including features like [structured outputs](/docs/inference/structured-outputs) and [caching](/docs/inference/caching), and handle regular **maintenance and backups** to keep your systems running smoothly.

This approach allows your team to concentrate on developing AI applications rather than managing the underlying infrastructure complexity.

## WorkflowAI does not cost more

**You pay exactly the same as going direct to providers.**

**How we make this work:** Individual customers typically buy tokens from providers because their usage is sporadic, and they can't justify renting GPUs that sit idle most of the time. WorkflowAI pools demand from many customers, creating consistent 24/7 throughput that maximizes GPU utilization. This allows us to rent GPU capacity directly instead of buying tokens, securing efficiently cheaper rates per token. We pass the standard token pricing to you while capturing the cost savings from efficient GPU utilization.

Most customers actually save money because they can quickly identify and switch to cheaper models that meet their performance (quality, latency) requirements.

Read more about [our pricing and business model](/docs/pricing).

<Card
  title="Ready to get started?"
  description="Get started with WorkflowAI in minutes"
  href="/docs/quickstarts"
/>