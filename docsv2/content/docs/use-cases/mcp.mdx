---
title: "Building AI Agents with AI agents."
summary: A collection of use-case scenarios for AI agents that interact with the WorkflowAI platform. Outlines the required capabilities for agents to perform tasks like optimization, debugging, and deployment.
---

## AX: Agent Experience

<Callout type="info">
  https://biilmann.blog/articles/introducing-ax/
</Callout>

**AX (Agent Experience)** refers to the holistic experience an AI agent has when interacting with a product, platform, or digital service.

As software evolves to support autonomous and collaborative AI agents, AX becomes a key design discipline—just like UX (User Experience) and DX (Developer Experience).

### Core Principles of AX:
- **Agent Usability**: Is the platform easy for an agent to use without human assistance?
- **Machine-Readable Interfaces**: Are APIs and documentation structured in a way that LLMs can understand and navigate?
- **Context-Aware Flows**: Can agents execute meaningful tasks with minimal prompting or clarification?
- **Autonomy and Collaboration**: Does the system support both independent agent actions and agent-human collaboration?

### Why AX Matters:
- Agents are emerging as a new type of user.
- Software optimized for AX will be more powerful, efficient, and interoperable.
- Open platforms with strong AX will attract broader agent ecosystems and unlock exponential value for users.

> AX is not about adding AI features—it's about **designing for AI agents as first-class users.**

## Glossary

Each scenario in this document describes three key components:

- **Initial state**: The representation of where the user's current setup is before the task begins. This includes existing code, infrastructure, or tools already in place.

- **Goal**: Describes exactly what the user will ask their AI agent to accomplish. This is written from the perspective of an end-user interacting with AI coding assistants like Cursor, Codex, etc.

- **What is required**: A first draft of the list of capabilities (i.e., MCP tools) that the AI agent will need to successfully achieve the stated goal. These represent the underlying functionalities and integrations required.

## Why WorkflowAI for Agents

- API-first management. WorkflowAI's API lets platforms, developers and agents .... programatically. Everythin from ... to .. is accessible via well-documented endpoints. 
- 100% compatible with OpenAI's API. Agents are already training on using OpenAI's API and can run any compatible integrations as well.
- Provider agnostic. You can use WorkflowAI with any model provider. There is also no setup required to try a new provider, since API keys are managed by WorkflowAI directly. 

> Reference: https://neon.com/blog/netlify-db-powered-by-neon#why-neon-for-agents

## Scenario 1: Build Text Summarization Agent from Scratch

### intial state:
```python
(empty repo)
```

### goal: (as the end-user would write in Codex, Cursor, etc.)
```
- write a AI agent that can summarize a text. if there is a URL in the text, extract the text from the URL to be able to write an accurate summary. 
- find a model that works well for this task 
- and is cheap. 

give me 3 options (models) from choose from with pros and cons.
```

### what is required:
- a way to get the code of the agent
- API keys
- a way to run the code for a given input to test it (either via the code, via the API directly)
- evaluate the output of the agent
- access the price
- access the tools available on the platform.
- ...

## Scenario 2: Optimize Agent Performance with Faster Models

### intial state:

```
- agent is running on OpenAI. 
```
```python
import openai

client = openai.OpenAI(api_key="sk-proj-1234567890")

prompt = """
<instructions> Analyze the provided conversation transcript to determine if it indicates a potential scam. Follow these steps:
Carefully examine the transcript.
Identify common scam indicators such as:
Requests for personal or financial information.
Promises of unrealistic rewards or gains.
Pressure to act quickly or threats of negative consequences.
Unusual or unsolicited payment requests.
Inconsistencies or vague details in the story.
Offers to help with financial issues without a valid reason.
Presence of unsolicited messages, especially those containing links or attachments.
Use of shortened URLs or suspicious links.
Determine the role of each participant to accurately identify the user exhibiting scam behavior.
Determine if the conversation is a scam:
If clear scam indicators are present, set is_scam to 'YES'.
Else if some suspicious elements are present, the transcript is long enough and you have enough context but not enough to confirm, set is_scam to 'UNSURE'.
Else if no scam indicators are found or more context is needed to determine if this is a scam or the transcript is too short to make a definitive determination if this is a scam, set is_scam to 'NO'.
Provide a concise reason explaining your determination, highlighting specific elements from the transcript that support your conclusion.
If you determine the conversation is a scam or potentially a scam, include the author_id of the user identified as the scammer in the scamer_id field.
Format the output with 'is_scam', 'reason', and 'scamer_id' fields. If the conversation is definitely not a scam, set 'scamer_id' to an empty string.
Ensure that the 'scamer_id' accurately corresponds to the "speakerId" field of the user exhibiting scam characteristics based on the transcript.
Example:
{
  "is_scam": "YES",
  "reason": "The message is unsolicited, contains a shortened link, and mentions a rewards credit with an urgent expiration date, which are common phishing tactics.",
  "scamer_id": "usr_1M3TB5BZ7D12X8KKBXT08HWEB4"
}
</instructions>
Input will be provided in the user message using a JSON following the schema:
{
  "type": "object",
  "properties": {
    "transcript": {
      "description": "The transcript of the conversation to be checked for scams",
      "type": "string"
    }
  }
}
Return a single JSON object enforcing the following schema:
{
  "type": "object",
  "properties": {
    "is_scam": {
      "description": "Indicates whether the conversation is a scam. Set to 'YES' if clear scam indicators are present and participants do not have a known relationship, 'NO' if no scam indicators are found, the transcript is too short, or participants have a known relationship, and 'UNSURE' if there are multiple suspicious elements but not enough to confirm.",
      "enum": [
        "YES",
        "NO",
        "UNSURE"
      ],
      "type": "string"
    },
    "reason": {
      "description": "The explanation for why the conversation is identified as a scam or not, highlighting specific elements from the transcript that support the conclusion, including the relationship between participants.",
      "type": "string",
      "examples": [
        "The transcript shows an unsolicited invitation to a webinar masterclass from a participant who does not have a prior relationship with the other party.",
        "Participants are known to each other and there are no clear scam indicators present.",
        "Multiple suspicious elements are present, but the relationship between participants makes it inconclusive."
      ]
    },
    "scamer_id": {
      "description": "The `author_id` of the user identified as the scammer. If `is_scam` is `'UNSURE'`, still include the `scammer_id`.",
      "examples": [
        "usr_QQTA93SZAH6XXFYK0E8190KA6M"
      ],
      "type": "string"
    }
  }
}
"""

user_input = """
{
  "transcript": "[{\"speakerId\":\"usr_WG87GX2W5H54N3E3KBQ32E9FPG\",\"text\":\"About:\\nDesoto Door is a local, family-owned company specializing in residential and commercial garage door services, including repair, installation, and maintenance. Established in 2009, the company is dedicated to providing high-quality, customizable garage door solutions.\\n\\nServices:\\n- Garage Door Installation: Professional installation of new garage doors tailored to customer preferences and architectural styles.\\n- Garage Door Repair: Expert repair services for garage doors, addressing issues such as jammed doors, spring, roller, and track repairs.\\n- Garage Door Opener Repair: Specialized repair services for garage door openers, ensuring smooth and reliable operation.\\n- Emergency Garage Door Services: 24/7 emergency repair services for urgent garage door issues.\\n- Gate Opener Installation and Repair: Installation and maintenance of automated gate openers with advanced access control technology.\\n\\nProducts:\\n- Residential Garage Doors: Offering a variety of styles including carriage-house, raised-panel, and modern designs with overhead operation. Available in multiple colors, finishes, and materials to enhance home aesthetics.\\n- Commercial Overhead Doors: Providing energy-efficient and durable overhead doors for commercial spaces, including sectional and rolling steel doors designed for safety and efficiency.\\n\\nPolicies:\\n- Repairs: Repair services are provided by certified technicians with a focus on quality and customer satisfaction.\\n\\nBusiness Hours:\\n- Mon - Friday 8-4\"}]"
}
"""

response = client.chat.completions.create(
    model="gpt-4o",
    messages=[
        {
            "role": "system",
            "content": prompt
        },
        {
            "role": "user",
            "content": user_input
        }
    ]
)

print(response.choices[0].message.content)
```

### goal:
```
- this AI agent is too slow, i want to use a faster model.
- make sure the faster model give similar results than the current model. 
- compare the faster models with the current model.
```

### what is required:
- create API keys

## Scenario 3: Migrate Agent from OpenAI to WorkflowAI

### intial state:

```
- agent is running on OpenAI.
```

### goal:
```
- i want to setup this agent on WorkflowAI.
- make no changes to the agent, model, keep everything the same.
- test that the agent is running fine on WorkflowAI.
- ...
```

### what is required:
- create API keys
- ...


## Scenario 4: Debug Agent Incorrect Output

### intial state:

```
- agent is running on WorkflowAI. 
this agent: https://workflowai.com/hearthands/agents/scam-detection/runs/01974351-2a58-7337-cabe-a4c8e1510b97
```

### goal:
```
- for this run https://workflowai.com/hearthands/agents/scam-detection/runs/01974351-2a58-7337-cabe-a4c8e1510b97, the correct answer was "YES". 
- i want to know why the agent gave the wrong answer. and what would you do to improve the agent. 
```

### what is required:
- ...

## Scenario 5: Edit Agent in Playground and Sync to IDE

### initial state:
```
- agent is running on WorkflowAI
- user has the agent code in their IDE (VSCode, Cursor, etc.)
```

### goal:
```
- open the WorkflowAI playground to edit the agent
- experiment with different prompts and configurations in the playground
- find a new version that works better
- get the updated agent code back into my IDE
```

### what is required:
- ability to open/launch WorkflowAI playground from IDE
- download/export agent code from WorkflowAI platform

## Scenario 6: Investigate User's Bad Agent Experience

<Callout type="info">
  This scenario is the one we are getting internally with issues being reported to Yann's with the playground agent.
  Demo a specific and real issue.
</Callout>

### initial state:
```
- agent is deployed on WorkflowAI in production
- agent logs all runs with metadata including "user_id"
```

### goal:
```
- user_id "usr_12345" just got a bad experience with agent "agent_abc123"
- find out what happened in that specific interaction
- analyze the agent's behavior for that user
- identify potential issues or failure points
- understand if this is a recurring problem for this user or others
```

### what is required:
- ability to query runs by user_id and agent_id
- retrieve specific run details and execution traces
- ...

## Scenario 7: Fix User Bug When Agent Lacks Metadata Tracking

### initial state:
```
- agent is deployed on WorkflowAI in production
- agent is NOT collecting user_id or other metadata for runs
```

### goal:
```
- user_id "usr_67890" reports a bug with agent "agent_xyz789"
- fix this bug for this specific user
- but first need to implement proper metadata collection
- then investigate and resolve the user's issue
```

### what is required:
- modify agent code to collect user_id metadata for all runs
- deploy updated agent with metadata tracking

## Scenario 8: Evaluate New OpenAI Model Performance

### initial state:
```
- agent is running on WorkflowAI with current model (e.g., gpt-4o)
- agent has historical performance data
- new OpenAI model is available (e.g., gpt-4o-2024-11-20)
```

### goal:
```
- try how the new model from OpenAI performs on this agent
- compare quality, speed, and cost between current and new model
- decide whether to upgrade the agent to use the new model
```

### what is required: (AI generated)
- ability to duplicate/clone existing agent with new model configuration
- access to run the same prompts/inputs on both model versions
- quality comparison tools to evaluate output differences
- A/B testing capabilities to run parallel experiments
- access to latency metrics for both models
- cost analysis and reporting for token usage comparison
- performance benchmarking tools
- ability to run test suites against both model versions
- statistical analysis to determine significance of differences
- rollback capabilities if new model underperforms
- gradual rollout tools to test with subset of users first

## Scenario 9: Get Latest Updates from WorkflowAI Platform

### initial state:
```
(do not matter)
```

### goal:
```
- get the latest updates from WorkflowAI platform and update the code to benefit
```

### what is required: (AI generated)
- access to WorkflowAI platform changelog or release notes
- ability to fetch latest platform updates and new features
- understand which updates are relevant to current agent implementation
- modify agent code to leverage new platform capabilities
- test updated agent with new features
- migrate existing configurations to utilize new improvements
- access to platform API documentation for new endpoints or parameters

## Scenario 10: Ask WorkflowAI for Agent Improvement Recommendations

### initial state:
```
- any agent file
```

### goal:
```
- can you ask WorkflowAI how to improve this agent?
```

### what is required:
- ...

## Scenario 11: Setup Deployments on Existing Agent

### initial state:
```
- agent code is available in IDE
```

### goal:
```
- setup deployments on this agent
ALT:
- I want to be able to update this agent without changing any code using WorkflowAI.
```

### what is required:
- ...

## Scenario 12: Deploy Specific Agent Version

### initial state:
```
(does not matter)
```

### goal:
```
- deploy this version to production on WorkflowAI.
```

### what is required:
- ...

## Scenario 13: Create Evaluation Script for Agent Testing

### Customer Request:
> "Hey, thanks for your help with the fraud detection agent! 
> 
> So Pierre was probably talking about reviews indeed. I started using reviews that help, but it forces us to use a manual approach.
> 
> First I'll talk about the need instead of jumping into the solution:
> - The need is to assess whether an AI agent is reliable enough to be deployed into production with barely anyone monitoring  
> - For several AI agents, we have a lot of past data that we had to analyze ourselves, with input and output
> - For example, we're working on an email campaign fraud alert, and we have thousands of emails and whether they should be flagged as fraud or not
> 
> As to how I imagine the process:
> - First I build the agent, and define its schema
> - I format a csv/xlsx/JSON file that contains a relatively high number of rows (up to 1000 should be enough I'd say, but the more the better), with one row per run, and one column per input and expected output (if agent has 2 inputs - email subject and email content - and 2 outputs - boolean is_fraud and a number for the confidence, that would make 4 columns)  
> - I upload the file in WorkflowAI, I chose the AI agent version I want to test
> - It runs for a while
> - I get a comparison of output vs expected_output (% that match, list of non-matching inputs to dig further)
> 
> Right now we can try to do this via scripts but it's only feasible for devs, not PMs
> 
> Hope that helps!"

### initial state:
```
- agent is deployed on WorkflowAI (e.g., email fraud detection agent)
- user has a CSV/JSON dataset with test cases containing inputs and expected outputs
- dataset format: email_content, expected_is_fraud, expected_confidence_score
```

### goal:
```
- create a script that can automatically test my agent against this dataset
- run the agent on each test case and compare actual vs expected results
- generate a report showing accuracy, precision, recall, and specific failure cases
- identify which test cases the agent got wrong so I can improve the prompts
- make it easy to re-run this evaluation after making changes to the agent
```

### what is required:
- ability to load and parse the evaluation dataset (CSV/JSON/XLSX)
- programmatic access to run the agent on each test case via WorkflowAI API
- comparison logic to evaluate actual vs expected outputs
- statistical analysis to calculate performance metrics (accuracy, precision, recall, F1-score)
- report generation with detailed breakdown of results
- identification and logging of specific failure cases with reasons
- ability to save evaluation results for comparison across agent versions
- batch processing capabilities for large datasets (up to 1000+ rows)
- error handling for API failures or malformed responses
- configurable evaluation criteria (exact match vs semantic similarity)
- user-friendly interface accessible to PMs, not just developers

## Scenario 14: Add Memory Feature to Conversation Agent

### initial state:
```
- basic chat agent that responds to user messages
- agent has no memory between conversations 
```

### goal:
```
- I want to add memory to my conversation agent so it can remember previous interactions
- The agent should remember user preferences, previous topics discussed, and personal details shared
- Memory should persist across different chat sessions
- I want to be able to control what gets remembered and what gets forgotten
- Test that the memory is working correctly and the agent can recall information from previous conversations
- Make sure the memory doesn't slow down the agent too much
```

### what is required:
- TBD

# References

## Neon MCP 

https://neon.com/docs/ai/neon-mcp-server#supported-actions-tools lists the tools from the Neon MCP server. 
