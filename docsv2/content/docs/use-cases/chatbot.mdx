---
title: Building a Chatbot
summary: Build an intelligent conversational AI chatbot from scratch. This guide covers everything from basic setup and conversation management to advanced features like streaming, error handling, and deployment.
description: Learn how to build an intelligent conversational AI chatbot
---

# Building a Chatbot

This guide walks you through creating a conversational AI chatbot from scratch using our platform.

## Overview

A chatbot is an AI-powered application that can engage in natural conversations with users. In this guide, you'll learn how to build a chatbot that can:
- Understand user intent
- Maintain conversation context
- Provide helpful responses
- Handle edge cases gracefully

## Prerequisites

Before starting, ensure you have:
- An API key from your dashboard
- Basic knowledge of Python or JavaScript
- Understanding of REST APIs

## Step 1: Setting Up

First, install the necessary SDK:

```bash
# Python
pip install openai

# JavaScript
npm install openai
```

Initialize the client:

```python
from openai import OpenAI

client = OpenAI(
    api_key="YOUR_API_KEY"
)
```

## Step 2: Basic Chat Implementation

### Simple Request-Response

Start with a basic chat completion:

```python
def chat_with_bot(user_message):
    response = client.chat.completions.create(
        model="gpt-4",
        messages=[
            {"role": "system", "content": "You are a helpful assistant."},
            {"role": "user", "content": user_message}
        ]
    )
    return response.choices[0].message.content

# Test the chatbot
user_input = "Hello! What can you help me with?"
bot_response = chat_with_bot(user_input)
print(bot_response)
```

### Managing Conversation History

To maintain context, store the conversation history:

```python
class Chatbot:
    def __init__(self, system_prompt):
        self.messages = [
            {"role": "system", "content": system_prompt}
        ]
    
    def chat(self, user_message):
        # Add user message to history
        self.messages.append({"role": "user", "content": user_message})
        
        # Get response
        response = client.chat.completions.create(
            model="gpt-4",
            messages=self.messages
        )
        
        # Add assistant response to history
        assistant_message = response.choices[0].message.content
        self.messages.append({"role": "assistant", "content": assistant_message})
        
        return assistant_message

# Initialize chatbot
bot = Chatbot("You are a friendly customer support assistant.")

# Have a conversation
print(bot.chat("Hi, I need help with my order"))
print(bot.chat("My order number is 12345"))
print(bot.chat("When will it arrive?"))
```

## Step 3: Advanced Features

### Streaming Responses

For better user experience, stream responses in real-time:

```python
def stream_chat(messages):
    stream = client.chat.completions.create(
        model="gpt-4",
        messages=messages,
        stream=True
    )
    
    for chunk in stream:
        if chunk.choices[0].delta.content is not None:
            print(chunk.choices[0].delta.content, end="")
```

### Adding Personality

Customize your chatbot's personality with detailed system prompts:

```python
personality_prompts = {
    "professional": """You are a professional business assistant. 
                      Maintain a formal tone, be concise, and focus on efficiency.""",
    
    "friendly": """You are a warm and friendly assistant. 
                   Use casual language, emojis occasionally, and be encouraging.""",
    
    "technical": """You are a technical expert assistant. 
                    Provide detailed explanations and use technical terminology when appropriate."""
}

# Create a professional chatbot
professional_bot = Chatbot(personality_prompts["professional"])
```

### Handling Special Commands

Implement command handling for enhanced functionality:

```python
class AdvancedChatbot(Chatbot):
    def process_command(self, message):
        if message.startswith("/help"):
            return "Available commands:\n/help - Show this message\n/reset - Clear conversation\n/mode - Change chatbot mode"
        elif message.startswith("/reset"):
            self.messages = [self.messages[0]]  # Keep system prompt
            return "Conversation reset!"
        elif message.startswith("/mode"):
            # Implement mode switching logic
            return "Mode switching coming soon!"
        return None
    
    def chat(self, user_message):
        # Check for commands first
        command_response = self.process_command(user_message)
        if command_response:
            return command_response
        
        # Otherwise, proceed with normal chat
        return super().chat(user_message)
```

## Step 4: Error Handling and Rate Limiting

### Implement Retry Logic

```python
import time
from openai import RateLimitError, APIError

def chat_with_retry(messages, max_retries=3):
    for attempt in range(max_retries):
        try:
            response = client.chat.completions.create(
                model="gpt-4",
                messages=messages
            )
            return response.choices[0].message.content
        except RateLimitError:
            if attempt < max_retries - 1:
                wait_time = 2 ** attempt  # Exponential backoff
                print(f"Rate limit hit. Waiting {wait_time} seconds...")
                time.sleep(wait_time)
            else:
                raise
        except APIError as e:
            print(f"API error: {e}")
            raise
```

### Token Management

Monitor and manage token usage:

```python
def estimate_tokens(text):
    # Rough estimation: 1 token â‰ˆ 4 characters
    return len(text) // 4

class TokenAwareChatbot(Chatbot):
    def __init__(self, system_prompt, max_tokens=4000):
        super().__init__(system_prompt)
        self.max_tokens = max_tokens
    
    def trim_history(self):
        # Keep system message and recent messages
        total_tokens = 0
        kept_messages = [self.messages[0]]  # System message
        
        for message in reversed(self.messages[1:]):
            tokens = estimate_tokens(message["content"])
            if total_tokens + tokens < self.max_tokens:
                kept_messages.insert(1, message)
                total_tokens += tokens
            else:
                break
        
        self.messages = kept_messages
```

## Step 5: Integration and Deployment

### Web Interface

Create a simple web interface using Flask:

```python
from flask import Flask, request, jsonify

app = Flask(__name__)
chatbot = Chatbot("You are a helpful assistant.")

@app.route('/chat', methods=['POST'])
def chat():
    user_message = request.json.get('message')
    if not user_message:
        return jsonify({'error': 'No message provided'}), 400
    
    try:
        response = chatbot.chat(user_message)
        return jsonify({'response': response})
    except Exception as e:
        return jsonify({'error': str(e)}), 500

if __name__ == '__main__':
    app.run(debug=True)
```

### Frontend Integration

Simple HTML/JavaScript frontend:

```html
<!DOCTYPE html>
<html>
<head>
    <title>AI Chatbot</title>
</head>
<body>
    <div id="chat-container">
        <div id="messages"></div>
        <input type="text" id="user-input" placeholder="Type your message...">
        <button onclick="sendMessage()">Send</button>
    </div>

    <script>
        async function sendMessage() {
            const input = document.getElementById('user-input');
            const message = input.value;
            if (!message) return;

            // Display user message
            displayMessage('You: ' + message);
            input.value = '';

            // Send to backend
            try {
                const response = await fetch('/chat', {
                    method: 'POST',
                    headers: {'Content-Type': 'application/json'},
                    body: JSON.stringify({message: message})
                });
                const data = await response.json();
                displayMessage('Bot: ' + data.response);
            } catch (error) {
                displayMessage('Error: ' + error.message);
            }
        }

        function displayMessage(message) {
            const messagesDiv = document.getElementById('messages');
            messagesDiv.innerHTML += '<p>' + message + '</p>';
            messagesDiv.scrollTop = messagesDiv.scrollHeight;
        }
    </script>
</body>
</html>
```

## Best Practices

1. **Context Management**: Keep conversation history relevant and within token limits
2. **Error Handling**: Always implement proper error handling and fallbacks
3. **User Experience**: Use streaming for long responses and provide typing indicators
4. **Safety**: Implement content filtering and moderation
5. **Analytics**: Log conversations for improvement (with user consent)
6. **Testing**: Test edge cases and unexpected inputs thoroughly

## Next Steps

- Explore [function calling](/docs/inference#function-calling) for enhanced capabilities
- Implement [structured outputs](/docs/inference/structured-outputs) for consistent responses
- Add [observability](/docs/observability) to monitor performance
- Consider [fine-tuning](/docs/deployments) for specialized use cases

## Example Projects

Check out these example implementations:
- [Customer Support Chatbot](https://github.com/example/support-bot)
- [Educational Assistant](https://github.com/example/edu-bot)
- [Multi-lingual Chatbot](https://github.com/example/multilingual-bot) 